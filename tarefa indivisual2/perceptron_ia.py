# -*- coding: utf-8 -*-
"""Perceptron IA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TCo1l3KJo9znlbDckI7osLzAgiwbvXac
"""

import numpy as np
import matplotlib.pyplot as plt # Importa matplotlib para o gráfico

# Dados fornecidos
w_initial = np.array([0.2, -0.1, 0.5]) #
X = np.array([[1, 0, 1, 1],
              [0, 1, 1, 0],
              [1, 0, 1, 1]]) #
d = np.array([1, 0, 1, 0]) #
eta = 1 #taxa de aprendizado

# A função de ativação degrau será f(u) = 1 se u >= 0, 0 caso contrário.
def step_function(u_val):
    return 1 if u_val >= 0 else 0

current_w = w_initial
# Inicializa a variável 'current_w' com os pesos iniciais definidos.
# 'current_w' irá armazenar os pesos do Perceptron e será atualizada durante o treinamento.

converged = False
# Inicializa uma flag booleana 'converged' como False.
# Esta flag será True se o Perceptron classificar todas as amostras corretamente em uma iteração.

num_iterations = 3

print("--- Início das",num_iterations, "Iterações de Treinamento do Perceptron (SEM BIAS) ---")
print(f"Amostras de Entrada (X):\n{X.T}")
print(f"Saídas Desejadas (d): {d}")
print(f"Pesos Iniciais w(0): {w_initial}") #
print(f"Taxa de Aprendizado (eta): {eta}\n") #

errors_per_iteration = [] # Lista para armazenar o número de erros por iteração
# Esta lista será usada para armazenar o número total de erros que ocorreram em cada iteração completa.


for iteration in range(1, num_iterations + 1):#
    print(f"\n--- Iteração {iteration} ---")
    print(f"Pesos atuais w({iteration-1}): {current_w}\n")

    errors_in_current_iteration = 0 # Conta erros nesta iteração
    all_correct_in_iteration = True

    for i in range(X.shape[1]):  # Passando pelas n amostras
        # Inicia um loop aninhado que percorre cada amostra de entrada em 'X'.
        # 'X.shape[1]' retorna o número de colunas (amostras) na matriz 'X'.
        x_sample = X[:, i]
        # Seleciona a i-ésima coluna de 'X' como a amostra de entrada atual.
        # '[:, i]' significa todas as linhas para a coluna 'i'.
        d_sample = d[i]
        # Seleciona a saída desejada correspondente para a amostra atual do array 'd'.


        # 1. O somatório: u = w * x (SEM BIAS)
        u = np.dot(current_w, x_sample)
        # Calcula o somatório ponderado ('u') como o produto escalar dos pesos atuais ('current_w')
        # pela amostra de entrada atual ('x_sample').
        print(f"  Amostra {i+1} (x={x_sample.tolist()}, d={d_sample}):")
        print(f"    Somatório u = w_atual * x = {np.round(u, 2)}")

        # 2. A saída: y = f(u) (SEM BIAS)
        y = step_function(u)
        print(f"    Saída y = f({np.round(u, 2)}) = {y}")

        # 3. O erro: e = d - y
        error = d_sample - y
        print(f"    Erro e = d - y = {d_sample} - {y} = {error}")

        # 4. A atualização dos pesos (SEM BIAS)
        if error != 0:
            delta_w = eta * error * x_sample
            print(f"    delta_W =",delta_w)
            current_w = current_w + delta_w
            all_correct_in_iteration = False # Houve um erro, então não convergiu nesta iteração
            errors_in_current_iteration += 1 # Incrementa o contador de erros
            print(f"    Atualização de pesos: w_nova = w_atual + eta * e * x = {np.round(current_w - delta_w, 2)} + {eta} * {error} * {x_sample.tolist()} = {np.round(current_w, 2)}") #
        else:
            print("    Erro = 0. Sem atualização de pesos.")

        print(f"    Novos pesos w: {np.round(current_w, 2)}\n")

    errors_per_iteration.append(errors_in_current_iteration) # Adiciona o total de erros da iteração à lista

    if all_correct_in_iteration:
        converged = True
        print(f"\n--- Convergência alcançada na Iteração {iteration}! ---")
        break # Sai do loop principal se convergir

if not converged:
    print(f"\n--- Fim das {num_iterations} Iterações (Não Convergiu) ---")
else:
    print(f"\n--- Perceptron Convergiu na Iteração {iteration} ---")

print(f"\nPesos Finais w: {np.round(current_w, 2)}")

# --- Geração do Gráfico ---
plt.figure(figsize=(10, 6))
plt.plot(range(1, len(errors_per_iteration) + 1), errors_per_iteration, marker='o', linestyle='-', color='b')
plt.title('Número de Erros por Iteração no Treinamento do Perceptron (SEM BIAS)')
plt.xlabel('Iteração')
plt.ylabel('Número de Erros')
plt.xticks(range(1, len(errors_per_iteration) + 1)) # Mostra todas as iterações no eixo X
plt.grid(True)
plt.show() # Mostra o gráfico